{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data_manager\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer\n",
    "from kirby.run_params import RunParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manager\n",
    "\n",
    "> Prepares and Loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataManager():\n",
    "    def __init__(self, run_params):\n",
    "        self.run_params = run_params\n",
    "        self.block_size = 128\n",
    "    # Load, Tokenize, and Augment data\n",
    "    def prepare_data(self):\n",
    "        train_ds, val_ds = map(self.prepare_ds, ('train', 'valid'))\n",
    "        return train_ds, val_ds\n",
    "    \n",
    "    def prepare_ds(self, split):\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(self.run_params.model)\n",
    "        tokenizer.pad_token = tokenizer.eos_token \n",
    "        split = f'{split}[:{self.run_params.batch_size*self.block_size if self.run_params.debug else f\"{self.run_params.data_set_percentage}%\"}]'\n",
    "        ds = load_dataset(self.run_params.data_file_type, data_files=self.run_params.data_files, split=split)\n",
    "        ds = ds.filter(function=self.criteria)\n",
    "        ds = ds.map(self.tokenize, batched=True, num_proc=4, remove_columns=['text'], fn_kwargs={'tokenizer':tokenizer})\n",
    "        ds = ds.map(\n",
    "            self.group_texts,\n",
    "            batched=True,\n",
    "#             batch_size=self.block_size,\n",
    "#             num_proc=self.run_params.num_workers\n",
    "        )\n",
    "        ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "        return ds\n",
    "\n",
    "    # Tokenize a sequence\n",
    "    def tokenize(self, x, tokenizer=None):\n",
    "        tokens = tokenizer(x['text'])\n",
    "        return tokens\n",
    "    \n",
    "    def group_texts(self, examples):\n",
    "        # Concatenate all texts.\n",
    "        concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "        total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "        # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "            # customize this part to your needs.\n",
    "        total_length = (total_length // self.block_size) * self.block_size\n",
    "        if total_length == 0:\n",
    "            total_length = self.block_size\n",
    "        # Split by chunks of max_len.\n",
    "        result = {\n",
    "            k: [t[i : i + self.block_size] for i in range(0, total_length, self.block_size)]\n",
    "            for k, t in concatenated_examples.items()\n",
    "        }\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "    \n",
    "    def criteria(self, x):\n",
    "        x = x['text']\n",
    "        # Remove blanks\n",
    "        if len(x) == 1:\n",
    "            return False\n",
    "        # Remove headings\n",
    "        if x[0:2] == ' =':\n",
    "            return False\n",
    "        return True\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d64f335cc8a13d66\n",
      "Reusing dataset text (/home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-913970d3a7a8309a.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-d343d49cae84df08.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-bd75306c84ce1e89.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-71e5f93c3caeb9fa.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-ad73a0d313c66486.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-23f45fac5d2d6b55.arrow\n",
      "Using custom data configuration default-d64f335cc8a13d66\n",
      "Reusing dataset text (/home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-c6f75d3344094c50.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-ee9df5fa9114f1d6.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-1cd3e09abeae56c9.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-1c49de6e66bab7be.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-dfc0148b180fa457.arrow\n",
      "Loading cached processed dataset at /home/rob/.cache/huggingface/datasets/text/default-d64f335cc8a13d66/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-c0ccee6969033717.arrow\n"
     ]
    }
   ],
   "source": [
    "# Creation\n",
    "from datasets import Dataset\n",
    "run_params = RunParams()\n",
    "data_manager = DataManager(run_params)\n",
    "train_ds, valid_ds = data_manager.prepare_data()\n",
    "assert isinstance(train_ds, Dataset)\n",
    "assert isinstance(valid_ds, Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'input_ids': tensor([ 2311,    73, 13090,   645,   569, 18354,  7496,   513,  1058,   791,\n",
       "         47398, 17740,   357,  4960,  1058, 10545,   230,    99,   161,   254,\n",
       "           112,  5641, 44444,  9202, 25084, 24440, 12675, 11839,    18,   837,\n",
       "          6578,   764,   569, 18354,  7496,   286,   262, 30193,   513,  1267,\n",
       "           837,  8811,  6412,   284,   355,   569, 18354,  7496, 17740,  6711,\n",
       "          2354,  2869,   837,   318,   257, 16106,  2597,  2488,    12,    31,\n",
       "          2712,  2008,   983,  4166,   416, 29490,   290,  6343,    13, 44206,\n",
       "           329,   262, 14047, 44685,   764, 28728,   287,  3269,  2813,   287,\n",
       "          2869,   837,   340,   318,   262,  2368,   983,   287,   262,   569,\n",
       "         18354,  7496,  2168,   764, 12645,   278,   262,   976, 21748,   286,\n",
       "         16106,   290,  1103,  2488,    12,    31,   640, 11327,   355,   663,\n",
       "         27677,   837,   262,  1621,  4539, 10730,   284,   262,   717,   983,\n",
       "           290,  5679,   262,   366, 17871,  5321,   366,   837]),\n",
       " 'labels': tensor([ 2311,    73, 13090,   645,   569, 18354,  7496,   513,  1058,   791,\n",
       "         47398, 17740,   357,  4960,  1058, 10545,   230,    99,   161,   254,\n",
       "           112,  5641, 44444,  9202, 25084, 24440, 12675, 11839,    18,   837,\n",
       "          6578,   764,   569, 18354,  7496,   286,   262, 30193,   513,  1267,\n",
       "           837,  8811,  6412,   284,   355,   569, 18354,  7496, 17740,  6711,\n",
       "          2354,  2869,   837,   318,   257, 16106,  2597,  2488,    12,    31,\n",
       "          2712,  2008,   983,  4166,   416, 29490,   290,  6343,    13, 44206,\n",
       "           329,   262, 14047, 44685,   764, 28728,   287,  3269,  2813,   287,\n",
       "          2869,   837,   340,   318,   262,  2368,   983,   287,   262,   569,\n",
       "         18354,  7496,  2168,   764, 12645,   278,   262,   976, 21748,   286,\n",
       "         16106,   290,  1103,  2488,    12,    31,   640, 11327,   355,   663,\n",
       "         27677,   837,   262,  1621,  4539, 10730,   284,   262,   717,   983,\n",
       "           290,  5679,   262,   366, 17871,  5321,   366,   837])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
