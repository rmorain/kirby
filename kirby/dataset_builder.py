# AUTOGENERATED! DO NOT EDIT! File to edit: 01_dataset_builder.ipynb (unless otherwise specified).

__all__ = ['DatasetBuilder']

# Cell
import random
from rake_nltk import Rake
from .database_proxy import WikiDatabase
import json
import importlib
import spacy
import en_core_web_sm
import tensorflow_hub as hub
from sklearn.neighbors import NearestNeighbors
import json

# Cell
class DatasetBuilder():
    "Build a dataset using `get_entities_in_text`"
    def __init__(self):
        self.rake = Rake()
        self.db = WikiDatabase()
        self.nlp = en_core_web_sm.load()
        module_url = "https://tfhub.dev/google/universal-sentence-encoder/4" #@param ["https://tfhub.dev/google/universal-sentence-encoder/4", "https://tfhub.dev/google/universal-sentence-encoder-large/5"]
        self.encoder = hub.load(module_url)

    def build(self, ds, dataset_type='random'):
        "Build a database based a given dataset"
        if dataset_type == 'random':
            return ds.map(self.random, batched=False)
        elif dataset_type == 'description':
            return ds.map(self.description, batched=False)
        elif dataset_type == 'relevant':
            pass

    def description(self, sequence):
        """Return a description augmented version of the seqeuence `text`"""
        text = sequence['text']
        try:
            keyword_entity = self._keyword_entity(text)
            json_string = self._get_json(keyword_entity)
            # Return concatenated string
            sequence['text'] += " " + json_string
        except Exception as e:
            # We expect there to be an exception when no entities are found
            pass
        return sequence

    def _keyword_entity(self, text):
        """Return the entity of the highest ranked keyword"""
        ranked_phrases = self.get_ranked_phrases(text)
        for phrase in ranked_phrases:
            entity = self.db.get_entity_by_label(phrase)
            if entity:
                return entity
        return None

    def _get_json(self, item):
        """Return JSON version of list object"""
        d = {"label": None, "description": None}
        d['label'] = item[1]
        d['description'] = item[2]
        return json.dumps(d)

    def keyword(self, x):
        ranked_phrases = self.get_ranked_phrases(x)
        return ranked_phrases[0]

    def get_ranked_phrases(self, x):
        self.rake.extract_keywords_from_text(x)
        return self.rake.get_ranked_phrases()

    #staticmethod
    def add_to_accepted(self, a_sentences, sentence):
        if len(a_sentences) > 2:
            a_sentences.pop(0)
        a_sentences.append(sentence)


    def get_entities_in_text(self, text):
        "Returns entities found in the sentence `text`"
        doc = self.nlp(text)
        entities = []
        spacy_entities = doc.ents
        for entity in spacy_entities:
            entity = self.db.get_entity_by_label(entity.text)
            if entity:
                entities.append(entity)
        return entities

    def get_entity_associations(self, entity_id):
        """
        Given an `entity_id` return a dictionary containing all the associated properties.
        """
        entity_associations_dict = {}
        # Remove all None values from list
        associations = self.db.get_entity_associations(entity_id)
        for property_id, related_entity_id in associations:
            property_name, related_entity_label = self.db.get_property_string(property_id, related_entity_id)
            entity_associations_dict[property_name] = related_entity_label
        return entity_associations_dict