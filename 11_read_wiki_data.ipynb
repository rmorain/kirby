{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp read_wiki_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read WikiData\n",
    "\n",
    "> Reads from wikidata database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kirby.create_database'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-72edb2ff6b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msqlite3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkirby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkirby\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kirby.create_database'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from qwikidata.json_dump import WikidataJsonDump\n",
    "import sqlite3\n",
    "import pandas\n",
    "import kirby.create_database\n",
    "from kirby.properties import properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# wjd = WikidataJsonDump('latest-all.json.bz2')\n",
    "\n",
    "\n",
    "# Make sure all string with apostrophes have an scape character for sql\n",
    "\n",
    "\n",
    "def fix_label(label):\n",
    "    index = 0\n",
    "    while index < len(label):\n",
    "        if label[index] == '\\'':\n",
    "            label = label[:index] + '\\'' + label[index:]\n",
    "            index += 1\n",
    "        index += 1\n",
    "    return label\n",
    "\n",
    "\n",
    "def write_to_file(conn, entities, properties, aliases):\n",
    "\n",
    "    for idx, item in enumerate(entities):\n",
    "        if idx % 1000 == 0:\n",
    "            conn.write(\"\\n\\n\\n\\nINSERT INTO Entities\\n (entity_id, label, description)\\n VALUES\\n\")\n",
    "        if (idx + 1) % 1000 == 0 or idx == len(entities) - 1:\n",
    "            item = item[:-1] + ';'\n",
    "        conn.write('{}\\n'.format(item))\n",
    "\n",
    "    for idx, item in enumerate(properties):\n",
    "        if idx % 1000 == 0:\n",
    "            conn.write(\n",
    "                \"\\n\\n\\n\\nINSERT INTO Properties_relations\\n (entity_id, relations)\\n VALUES\\n\")\n",
    "        if (idx + 1) % 1000 == 0 or idx == len(properties) - 1:\n",
    "            item = item[:-1] + ';'\n",
    "        conn.write('{}\\n'.format(item))\n",
    "\n",
    "    for idx, item in enumerate(aliases):\n",
    "        if idx % 1000 == 0:\n",
    "            conn.write(\"\\n\\n\\n\\nINSERT INTO Aliases\\n (entity_id, aliases)\\n VALUES\\n\")\n",
    "\n",
    "        if (idx + 1) % 1000 == 0 or idx == len(aliases) - 1:\n",
    "            item = item[:-1] + ';'\n",
    "        conn.write('{}\\n'.format(item))\n",
    "\n",
    "\n",
    "def write_to_database(conn, c, entities, properties, aliases):\n",
    "\n",
    "    query = []\n",
    "    for idx, item in enumerate(entities):\n",
    "        if idx % 1000 == 0:\n",
    "            query.append(\"INSERT INTO Entities\\n (entity_id, label, description)\\n VALUES\")\n",
    "\n",
    "        if (idx + 1) % 1000 == 0 or idx == len(entities) - 1:\n",
    "            query.append(item[:-1] + ';')\n",
    "            c.execute('\\n'.join(query))\n",
    "            query.clear()\n",
    "        else:\n",
    "            query.append(item)\n",
    "    query.clear()\n",
    "    for idx, item in enumerate(properties):\n",
    "        if idx % 1000 == 0:\n",
    "            query.append(\"INSERT INTO Properties_relations\\n (entity_id, relations)\\n VALUES\")\n",
    "\n",
    "        if (idx + 1) % 1000 == 0 or idx == len(properties) - 1:\n",
    "            query.append(item[:-1] + ';')\n",
    "            c.execute('\\n'.join(query))\n",
    "            query.clear()\n",
    "        query.append(item)\n",
    "    query.clear()\n",
    "\n",
    "    for idx, item in enumerate(aliases):\n",
    "        if idx % 1000 == 0:\n",
    "            query.append(\"INSERT INTO Aliases\\n (entity_id, aliases)\\n VALUES\")\n",
    "        if (idx + 1) % 1000 == 0 or idx == len(aliases) - 1:\n",
    "            query.append(item[:-1] + ';')\n",
    "            # print(query)\n",
    "            c.execute('\\n'.join(query))\n",
    "            query.clear()\n",
    "        else:\n",
    "            query.append(item)\n",
    "    conn.commit()\n",
    "\n",
    "\n",
    "def read_wiki_data(wjd, o_format, o_file):\n",
    "    items_list = []  # This will hold the data for the items\n",
    "    # items = {}  # Connected items go in the objects dictionary\n",
    "    max_entities = 100  # Variable to stop the program during testing\n",
    "    property_list = []  # List of all properties\n",
    "    aliases = []  # List of all aliases\n",
    "    conn = None\n",
    "    c = None\n",
    "    if o_format == 0:\n",
    "        conn = open('{}.txt'.format(o_file), 'a', encoding=\"utf-8\")\n",
    "    else:\n",
    "        # Create database\n",
    "        CreateDatabase.create_database(o_file)\n",
    "        # Connection to database\n",
    "        conn = sqlite3.connect('{}.db'.format(o_file))\n",
    "        c = conn.cursor()\n",
    "\n",
    "    for ii, entity_dict in enumerate(wjd):\n",
    "\n",
    "        if ii % 500 == 0 and ii != 0:\n",
    "            if o_format == 0:\n",
    "                write_to_file(conn, items_list, property_list, aliases)\n",
    "            else:\n",
    "                write_to_database(conn, c, items_list, property_list, aliases)\n",
    "\n",
    "            aliases.clear()\n",
    "            property_list.clear()\n",
    "            items_list.clear()\n",
    "        description = ''\n",
    "        # Store the id of the entity\n",
    "        entity_id = entity_dict['id']\n",
    "        index = 0\n",
    "\n",
    "        if 'descriptions' in entity_dict and 'en' in entity_dict['descriptions'] and 'value' in entity_dict['descriptions']['en']:\n",
    "            description = entity_dict['descriptions']['en']['value']\n",
    "\n",
    "        # Just keep the entities that have a name in English\n",
    "        if 'labels' in entity_dict:\n",
    "            if 'en' in entity_dict['labels']:\n",
    "                # temp = fix_label(entity_dict['labels']['en']['value'])\n",
    "                items_list.append('(\\'{}\\', \\'{}\\', \\'{}\\'),'.format(entity_id, fix_label(entity_dict['labels']['en']['value']),\n",
    "                                                                     fix_label(description)))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if 'aliases' in entity_dict:  # Create table\n",
    "            entity_aliases = []\n",
    "            if 'en-gb' in entity_dict['aliases']:\n",
    "                for element in entity_dict['aliases']['en-gb']:\n",
    "                    entity_aliases.append(fix_label(element['value']))\n",
    "            if 'en' in entity_dict['aliases']:\n",
    "                for element in entity_dict['aliases']['en']:\n",
    "                    entity_aliases.append(fix_label(element['value']))\n",
    "            if len(entity_aliases) > 0:\n",
    "                aliases.append('(\\'{}\\', \\'{}\\'),'.format(entity_id, ','.join(entity_aliases)))\n",
    "\n",
    "        if \"claims\" in entity_dict:\n",
    "            entity_properties = []\n",
    "            for inner_key in entity_dict[\"claims\"].keys():\n",
    "                if 'datavalue' in entity_dict[\"claims\"][inner_key][0]['mainsnak'] \\\n",
    "                        and ('value' in entity_dict[\"claims\"][inner_key][0]['mainsnak']['datavalue']) \\\n",
    "                        and isinstance(entity_dict[\"claims\"][inner_key][0]['mainsnak']['datavalue']['value'], dict) \\\n",
    "                        and ('id' in entity_dict[\"claims\"][inner_key][0]['mainsnak']['datavalue']['value']):\n",
    "                    entity_properties.append('({}, {})'.format(inner_key, entity_dict[\"claims\"][inner_key][0]['mainsnak']['datavalue']['value']['id']))\n",
    "            property_list.append('(\\'{}\\', \\'{}\\'),'.format(entity_id, ','.join(entity_properties)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the JSON path:  q\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "filename must end with \".json.bz2\" or \".json.gz\" or \".json\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b0dbcdc27cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-b0dbcdc27cd7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwjd_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the JSON path: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwjd_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mwiki_dump\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWikidataJsonDump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwjd_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     print(\"What output file do you want? a database file or a text file with insert statements?\",\n\u001b[1;32m      7\u001b[0m           '\\n0: text file\\n1: database file')\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/qwikidata/json_dump.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filename must end with \".json.bz2\" or \".json.gz\" or \".json\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: filename must end with \".json.bz2\" or \".json.gz\" or \".json\""
     ]
    }
   ],
   "source": [
    "#export\n",
    "def main():\n",
    "    wjd_name = input(\"Enter the JSON path: \")\n",
    "    print(wjd_name)\n",
    "    wiki_dump = WikidataJsonDump(wjd_name)\n",
    "    print(\"What output file do you want? a database file or a text file with insert statements?\",\n",
    "          '\\n0: text file\\n1: database file')\n",
    "    output_format = -1\n",
    "    while not (output_format == 0 or output_format == 1):\n",
    "        output_format = int(input('Please enter 0 or 1: '))\n",
    "    if output_format == 0:\n",
    "        output_file = input('Enter name of text file. Do not include .txt: ')\n",
    "    else:\n",
    "        output_file = input('Enter name of database file. Do not include .db: ')\n",
    "\n",
    "    read_wiki_data(wiki_dump, output_format, output_file)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
