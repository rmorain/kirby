{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dataset_builder\n",
    "#!pip install tensorflow\n",
    "# !pip install tensorflow_hub\n",
    "# !pip install spacy\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Builder\n",
    "> Builds an optimal dataset with knowledge base relations, from a vanilla dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#export \n",
    "import random\n",
    "from rake_nltk import Rake\n",
    "from kirby.database_proxy import WikiDatabase\n",
    "import json\n",
    "import importlib\n",
    "import spacy\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(kirby.database_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DatasetBuilder():\n",
    "    def __init__(self):\n",
    "        self.rake = Rake()\n",
    "        self.db = WikiDatabase()\n",
    "        self.nlp = spacy.load('en_core_web_sm')\n",
    "        pass\n",
    "    \n",
    "    def build(self, ds, dataset_type='random'):\n",
    "        \"Build a database based a given dataset\"\n",
    "        if dataset_type == 'random':\n",
    "            ds.map(self.random, batched=False)\n",
    "        elif dataset_type == 'description':\n",
    "            pass\n",
    "        elif dataset_type == 'relevant':\n",
    "            pass\n",
    "        \n",
    "    def keyword(self, x):\n",
    "        ranked_phrases = self.get_ranked_phrases(x)\n",
    "        return ranked_phrases[0]\n",
    "    \n",
    "    def random(self, x):\n",
    "        accepted_entities = []\n",
    "        ds_builder.rake.extract_keywords_from_text(x)\n",
    "        ranked_phrases = ds_builder.rake.get_ranked_phrases()\n",
    "        print(ranked_phrases)\n",
    "        keywords = self.keyword(x)\n",
    "        print(keywords)\n",
    "        print(self.db.get_entities_by_label_extensive('cristiano ronaldo'))\n",
    "        for entity in keywords: \n",
    "            print(entity)\n",
    "#             query_result = self.db.get_entity_by_label(entity)\n",
    "#             if len(query_result) == 0: \n",
    "#                 continue\n",
    "#             if len(query_result) > 1:\n",
    "#                 second_result = db.get_entities_by_label_extensive(entity)\n",
    "#                 rand_index = random.randint(0, len(second_result) - 1)\n",
    "#                 accepted_entities.append(second_result[rand_index])\n",
    "#             else:\n",
    "#                 accepted_entities.append(query_result[0])\n",
    "        return e\n",
    "    \n",
    "    def get_ranked_phrases(self, x):\n",
    "        self.rake.extract_keywords_from_text(x)\n",
    "        return self.rake.get_ranked_phrases()\n",
    "    \n",
    "    #staticmethod\n",
    "    def add_to_accepted(self, a_sentences, sentence):\n",
    "        if len(a_sentences) > 2:\n",
    "            a_sentences.pop(0)\n",
    "        a_sentences.append(sentence)\n",
    "    \n",
    "\n",
    "    def get_entities_in_text(self, x, random_entities=False):\n",
    "        accepted_sentence = []\n",
    "        accepted_entities = []\n",
    "        print(self.nlp)\n",
    "        doc = self.nlp(x)\n",
    "        print(doc)\n",
    "        for entity in doc.ents: \n",
    "            if entity.label_ == 'CARDINAL': \n",
    "                continue\n",
    "            print(entity.text, entity.label_)\n",
    "            result = self.db.get_entity_by_label(entity.text)\n",
    "            if len(result) == 0:\n",
    "                continue\n",
    "            elif len(result) > 1:\n",
    "                result = self.db.get_entities_by_label_extensive(entity.text)\n",
    "                if len(accepted_sentence) == 0 or random_entities:\n",
    "                    q_a_index = random.randint(0, len(result) - 1)\n",
    "                else:\n",
    "                    encoded_sentences = encoder(accepted_sentence)  # array of sentence vectors\n",
    "\n",
    "                    proposed_sentences = []\n",
    "                    for entity_w in result:\n",
    "                        # if entity_w[2] != '':\n",
    "                        proposed_sentences.append(entity_w[2])\n",
    "                    encoded_proposed = encoder(proposed_sentences)\n",
    "                    neigh = NearestNeighbors(n_neighbors=1)\n",
    "                    # print(proposed_sentences)\n",
    "                    neigh.fit(encoded_proposed)\n",
    "                    closest = neigh.kneighbors(encoded_sentences)\n",
    "                    q_a_index = closest[1][0][0]\n",
    "                self.add_to_accepted(accepted_sentence, result[q_a_index][2])\n",
    "                accepted_entities.append(result[q_a_index])\n",
    "\n",
    "            else:\n",
    "#                     print('Accepted:', result[0])\n",
    "                    self.add_to_accepted(accepted_sentence, result[0][2])\n",
    "                    accepted_entities.append(result[0]) \n",
    "        return accepted_entities\n",
    "\n",
    "    def entity(self, ranked_phrases):\n",
    "        \"Queries the knowledge base to find the entity and it's relations\"\n",
    "        for phrase in ranked_phrases:\n",
    "            entity = self.kba.get_entity(phrase)\n",
    "            if entity is not None:\n",
    "                return entity\n",
    "        return entity   \n",
    "    def get_entity_properties_strings(self, entity_id):\n",
    "        print(self.db.get_entity_properties(entity_id))\n",
    "        entity_properties_dict = {}\n",
    "        for entity_property in self.db.get_entity_properties(entity_id): \n",
    "            property_name, related_entity_label = self.db.get_property_string(entity_property[0], entity_property[1])\n",
    "            entity_properties_dict[property_name] = related_entity_label\n",
    "        return entity_properties_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creation\n",
    "ds_builder = DatasetBuilder()\n",
    "assert isinstance(ds_builder, DatasetBuilder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test ranked phrases\n",
    "# x = \"Stephen Curry is my favorite basketball player.\"\n",
    "# ds_builder.rake.extract_keywords_from_text(x)\n",
    "# ranked_phrases = ds_builder.rake.get_ranked_phrases()\n",
    "# ranked_phrases\n",
    "# for entity in ranked_phrases:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = \"Rachel Bilson posted that iconique throwback of herself and Rami Malek in high school\"\n",
    "entities = ds_builder.get_entities_in_text(x)\n",
    "for entity in entities: \n",
    "    print(entity)\n",
    "print(ds_builder.get_entity_properties_strings(entities[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random association\n",
    "x = \"Cristiano ronaldo played for Real Madrid\"\n",
    "random_association = ds_builder.random(x)\n",
    "random_association"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
